{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":15062,"databundleVersionId":545987,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import datasets, transforms\nimport torch.nn.functional as F\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-19T18:31:02.531710Z","iopub.execute_input":"2024-07-19T18:31:02.532313Z","iopub.status.idle":"2024-07-19T18:31:02.538875Z","shell.execute_reply.started":"2024-07-19T18:31:02.532277Z","shell.execute_reply":"2024-07-19T18:31:02.537752Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!unzip -q /kaggle/input/generative-dog-images/all-dogs.zip -d /kaggle/working/all-dogs/","metadata":{"execution":{"iopub.status.busy":"2024-07-19T18:31:03.681695Z","iopub.execute_input":"2024-07-19T18:31:03.682127Z","iopub.status.idle":"2024-07-19T18:31:21.906001Z","shell.execute_reply.started":"2024-07-19T18:31:03.682092Z","shell.execute_reply":"2024-07-19T18:31:21.904505Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image_files = os.listdir('/kaggle/working/all-dogs')\nprint(f'Number of images in the dataset = {len(image_files)}')","metadata":{"execution":{"iopub.status.busy":"2024-07-19T18:31:21.908888Z","iopub.execute_input":"2024-07-19T18:31:21.910138Z","iopub.status.idle":"2024-07-19T18:31:21.917265Z","shell.execute_reply.started":"2024-07-19T18:31:21.910081Z","shell.execute_reply":"2024-07-19T18:31:21.916051Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of images in the dataset = 1\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = '/kaggle/working/all-dogs'\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-07-19T18:31:21.918639Z","iopub.execute_input":"2024-07-19T18:31:21.919013Z","iopub.status.idle":"2024-07-19T18:31:21.934082Z","shell.execute_reply.started":"2024-07-19T18:31:21.918984Z","shell.execute_reply":"2024-07-19T18:31:21.932910Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize(64),\n    transforms.CenterCrop(64),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-19T18:31:21.937055Z","iopub.execute_input":"2024-07-19T18:31:21.937858Z","iopub.status.idle":"2024-07-19T18:31:21.947886Z","shell.execute_reply.started":"2024-07-19T18:31:21.937811Z","shell.execute_reply":"2024-07-19T18:31:21.946707Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = datasets.ImageFolder(PATH, transform=transforms)\ntrain_dataloader = torch.utils.data.DataLoader(train_data, \n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T18:31:21.949517Z","iopub.execute_input":"2024-07-19T18:31:21.950477Z","iopub.status.idle":"2024-07-19T18:31:22.081402Z","shell.execute_reply.started":"2024-07-19T18:31:21.950430Z","shell.execute_reply":"2024-07-19T18:31:22.080188Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    \n    def __init__(self, n_z, n_feats, n_channels):\n        super(Generator, self).__init__()\n        \n        self.conv1 = nn.ConvTranspose2d(in_channels=n_z, \n                                        out_channels=n_feats * 8, \n                                        kernel_size=4, \n                                        stride=1, \n                                        padding=0, \n                                        bias=False)\n        self.bn1 = nn.BatchNorm2d(num_features=n_feats * 8)\n        \n        self.conv2 = nn.ConvTranspose2d(in_channels=n_feats * 8,\n                                        out_channels=n_feats * 8,\n                                        kernel_size=4, \n                                        stride=2,\n                                        padding=1,\n                                        bias=False)\n        self.bn2 = nn.BatchNorm2d(num_features=n_feats * 8)\n        \n        self.conv3 = nn.ConvTranspose2d(in_channels=n_feats * 8, \n                                        out_channels=n_feats * 4,\n                                        kernel_size=4,\n                                        stride=2,\n                                        padding=1,\n                                        bias=False)\n        self.bn3 = nn.BatchNorm2d(num_features=n_feats * 4)\n        \n        self.conv4 = nn.ConvTranspose2d(in_channels=n_feats * 4,\n                                        out_channels=n_feats * 2,\n                                        kernel_size=4,\n                                        stride=2,\n                                        padding=1,\n                                        bias=False)\n        self.bn4 = nn.BatchNorm2d(num_features=n_feats * 2)\n        \n        self.conv5 = nn.ConvTranspose2d(in_channels=n_feats * 2,\n                                        out_channels=n_feats,\n                                        kernel_size=4,\n                                        stride=2,\n                                        padding=1, \n                                        bias=False)\n        self.bn5 = nn.BatchNorm2d(num_features=n_feats)\n        \n        self.conv6 = nn.ConvTranspose2d(in_channels=n_feats,\n                                        out_channels=n_channels,\n                                        kernel_size=3,\n                                        stride=1,\n                                        padding=1,\n                                        bias=False)\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.bn1(self.conv1(x)))\n        x = F.leaky_relu(self.bn2(self.conv2(x)))\n        x = F.leaky_relu(self.bn3(self.conv3(x)))\n        x = F.leaky_relu(self.bn4(self.conv4(x)))\n        x = F.leaky_relu(self.bn5(self.conv5(x)))\n        x = torch.tanh(self.conv6(x))\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-19T19:02:33.335112Z","iopub.execute_input":"2024-07-19T19:02:33.335530Z","iopub.status.idle":"2024-07-19T19:02:33.351453Z","shell.execute_reply.started":"2024-07-19T19:02:33.335495Z","shell.execute_reply":"2024-07-19T19:02:33.350230Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    \n    def __init__(self, n_channels, n_feats):\n        super(Discriminator, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=n_channels,\n                               out_channels=n_feats,\n                               kernel_size=4, \n                               stride=2,\n                               padding=1,\n                               bias=False)\n        \n        self.conv2 = nn.Conv2d(in_channels=n_feats,\n                               out_channels=n_feats * 2,\n                               kernel_size=4,\n                               stride=2,\n                               padding=1,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(num_features=n_feats * 2)\n        \n        self.conv3 = nn.Conv2d(in_channels=n_feats * 2,\n                               out_channels=n_feats * 4,\n                               kernel_size=4,\n                               stride=1,\n                               padding=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(num_features=n_feats * 4)\n        \n        self.conv4 = nn.Conv2d(in_channels=n_feats * 4,\n                               out_channels=n_feats * 8,\n                               kernel_size=4,\n                               stride=2,\n                               padding=1,\n                               bias=False)\n        self.bn4 = nn.BatchNorm2d(num_features=n_feats * 8)\n        \n        self.conv5 = nn.Conv2d(in_channels=n_feats * 8,\n                               out_channels=1,\n                               kernel_size=4,\n                               stride=1,\n                               padding=0,\n                               bias=False)\n        \n    def forward(self, x):\n        x = F.leaky_relu(self.conv1(x), 0.02)\n        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.02)\n        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.02)\n        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.02)\n        x = torch.sigmoid(self.conv5(x))\n        \n        return x.view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-19T19:02:34.055602Z","iopub.execute_input":"2024-07-19T19:02:34.056410Z","iopub.status.idle":"2024-07-19T19:02:34.069752Z","shell.execute_reply.started":"2024-07-19T19:02:34.056376Z","shell.execute_reply":"2024-07-19T19:02:34.068582Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nlr = 0.003\nbeta_1 = 0.5\n\nnetG = Generator(100, 32, 3).to(device)\nnetD = Discriminator(3, 48).to(device)\n\nloss_fn = nn.BCELoss()\n\noptimizerG = torch.optim.Adam(params=netG.parameters(),\n                              lr=lr,\n                              betas=(beta_1, 0.999))\noptimizerD = torch.optim.Adam(params=netD.parameters(),\n                              lr=lr,\n                              betas=(beta_1, 0.999))\n\nn_z = 100\nfixed_noise = torch.randn(25, n_z, 1, 1, device=device)\n\nreal_label = 0.9 # label-smoothing\nfake_label = 0.0\nbatch_size = train_dataloader.batch_size","metadata":{"execution":{"iopub.status.busy":"2024-07-19T19:06:08.801810Z","iopub.execute_input":"2024-07-19T19:06:08.802253Z","iopub.status.idle":"2024-07-19T19:06:08.860016Z","shell.execute_reply.started":"2024-07-19T19:06:08.802220Z","shell.execute_reply":"2024-07-19T19:06:08.858862Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}